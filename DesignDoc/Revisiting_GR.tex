\documentclass[12pt]{article}

%%%% Packages to be used
\usepackage{geometry}
\usepackage{graphicx}
% \graphicspath {{./../CleanSims/}}
\usepackage{amsmath, amssymb, amsfonts, amsthm, float}  
\usepackage{enumerate, color, framed, float, multirow}
\usepackage{comment, longtable, caption, subcaption, appendix}
\usepackage[sort,longnamesfirst]{natbib}
\usepackage{setspace, parskip}
\usepackage{placeins}

%%% Don't break up inline equations
% \binoppenalty=\maxdimen
% \relpenalty=\maxdimen


%%% Page Setup 
% \geometry{hmargin=3.5cm,vmargin={3cm,3cm},nohead,footskip=0.5in}
\renewcommand{\baselinestretch}{1.25}
\setlength{\baselineskip}{0.5in} \setlength{\parskip}{.05in}


\allowdisplaybreaks

%%% Table stretch
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{5pt}

%%% My Custom Commands
\newcommand{\pcite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}

\newcommand{\ds}{\displaystyle}
\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\X}{\mathsf{X}}
\newcommand{\Y}{\mathsf{Y}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\N}{{\mathbb N}}



\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newtheorem{theorem}{Theorem}
\newtheorem{defi}{Definition}
\newtheorem{propo}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}


\theoremstyle{remark}
\newtheorem{cond}{Condition}
\newtheorem{remark}{Remark}
\newtheorem{assum}{Assumption}
\newtheorem{example}{Example}



\begin{document}
\title{Revisiting the Gelman-Rubin Diagnostic}
\date{\today}
\author{Christina Knudson}
\maketitle


\section{Introduction} % (fold)
\label{sec:introduction}

The Gelman-Rubin (GR) diagnostic has been one of the most popular diagnostics for MCMC convergence. The GR diagnostic framework relies on  $m$  parallel chains ($m \geq 1$), each run for $n$ steps. The GR statistic (denoted $\hat{R}$) is the square root of the ratio of two estimators for the target variance.  In finite samples, the numerator overestimates this variance and the denominator underestimates it. Each estimator converges to the target variance, meaning that $\hat{R}$ converges to 1 as $n$ increases. When $\hat{R}$ becomes sufficiently close to 1, the GR diagnostic declares convergence. 





% section motivating_example (end)






\section{Effective Sample Size} % (fold)
\label{sec:choosing_delta}

For an estimator, Effective Sample Size (ESS) is the number of independent samples with the same standard error as a correlated sample. 

The following is an expression for the lugsail-based psrf $\hat{R}^p_L$ for $m$  chains, each of length $n$ with  p components.
\begin{align*}
	\hat{R}^p_L &= \sqrt{ \left(\dfrac{n-1}{n} \right) + \dfrac{m}{\widehat{\text{ESS}}_L}},
\end{align*}
Rearranging this yields an estimator of effective sample size:
\begin{align*}
\widehat{\text{ESS}}_L = \dfrac{m}{\left( \hat{R}^p_L \right)^2 -  \left(\dfrac{n-1}{n} \right)}.
\end{align*}

\begin{remark}
\textbf{Doots!!} I remember we discussed and mentioned that the total ESS is not just the sum of the individual chains' ESSs. But this kind of is. So... am I using the wrong equation?
\end{remark}
\begin{remark}
	\label{rem:minimum_effort}
\cite{vats:fleg:jones:2018} explain that a minimum simulation effort must be set to safeguard from premature termination due to early bad estimates of $\sigma^2$. We concur and  suggest  a minimum simulation effort of $n = M_{\alpha, \epsilon,p}$. \\
\end{remark}

\textbf{To Do} % (fold)


\begin{itemize}
 \renewcommand{\labelitemi}{$\square$}
\item[$\blacksquare$]  Add ESS calculation (now in \texttt{gr.diag} and \texttt{n.eff}).
\item[$\blacksquare$]  Add to \texttt{n.eff}. 
\begin{enumerate}
\item Call \texttt{target.psrf} using the info in their \texttt{mcmc.list} using  defaults.
\item Compare ESS to output of target.psrf and tell them whether this is sufficient for convergence.
\item If insufficient, calculate how many more samples needed using


\begin{align*}
\dfrac{n_\text{current}}{n_{ \text{current eff}}} \approx \dfrac{n_{\text{target}}}{n_{ \text{target eff}}}
\;\;\;  \Longrightarrow \;\;\;
 \dfrac{n_{\text{current}} \; n_{ \text{target eff}}}{n_{ \text{current eff}}}  \approx n_{\text{target}}.
\end{align*}
\item Added args of target.psrf.
\end{enumerate}
\item Create two functions: one to calculate $\hat{S}$ and another for $\hat{T}_L$. These two functions will be in the package but not exported. 
\item Rewrite \texttt{n.eff} to call these functions (rather than calling \texttt{gr.diag}).

%\item Figure out how to send some arguments from ellipsis of \texttt{n.eff} to \texttt{gr.diag} and others to \texttt{target.psrf}. 
\item Add an example.

\end{itemize}






\section{\textbf{Package building}}
\textbf{To do:}
\begin{itemize}
 \renewcommand{\labelitemi}{$\square$}
\item Clean up documentation
\item Add an example to \texttt{gr.diag} 
\item Check citations
\item Check descriptions and theory
\item Read through manual (pdf version)
\end{itemize}



\section{\textbf{Moving away from coda}}

Due to known coding errors (e.g. the miscalculated confidence interval for $\hat{R}$) and issues with \texttt{coda}, we would like to change our package (functions including \texttt{n.eff} and \texttt{gr.diag}) to no longer rely on \texttt{coda}. An incomplete list of ways we rely on  \texttt{coda}: 

\begin{itemize}
 \renewcommand{\labelitemi}{$\square$}
\item Users are required to input an \texttt{mcmc.list} in our current version. We should replace this with a list such that each object in the list is a matrix representing a single Markov chain: each row is one iteration and each column is one variable)
\item An \texttt{mcmclist} has \texttt{mcmc} objects. We will replace each mcmc object with a matrix (as described in the previous bullet). We need to keep in mind that \texttt{mcmc} performs several input checks, so we will need to perform our own checks. For example, we will need to check that all objects are of class matrix, and that the dims of each object in the list are identical. (do.call might be useful for this?)

\item Our code calls \texttt{niter} to find \texttt{n}; we can replace this with the number of rows in the first object of the list. I choose the first since all the objects should have the same dims so it wouldn't matter which we choose. We know we will have at least one Markov chain so we will have a first.
\item We call \texttt{nvar} to find \texttt{p}; we can replace this with the number of columns in the first object of the list. See note in previous bullet.
\end{itemize}








\bibliographystyle{apalike}
\bibliography{mcref}
\end{document}



